{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da86538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date      Open      High       Low     Close  \\\n",
      "0 2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667   \n",
      "1 2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667   \n",
      "2 2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000   \n",
      "3 2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   \n",
      "4 2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000   \n",
      "\n",
      "      Volume  Dividends  Stock Splits  \n",
      "0  281494500        0.0           0.0  \n",
      "1  257806500        0.0           0.0  \n",
      "2  123282000        0.0           0.0  \n",
      "3   77097000        0.0           0.0  \n",
      "4  103003500        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "#Question 1: Use yfinance to Extract Stock Data\n",
    "#Using the Ticker function enter the ticker symbol of the stock we want to extract data on to create a ticker object. \n",
    "#The stock is Tesla and its ticker symbol is TSLA.\n",
    "import yfinance as yf\n",
    "\n",
    "# Create ticker object for Tesla\n",
    "tesla = yf.Ticker(\"TSLA\")\n",
    "\n",
    "# Extract historical stock data with maximum period\n",
    "tesla_data = tesla.history(period=\"max\")\n",
    "\n",
    "# Reset index inplace\n",
    "tesla_data.reset_index(inplace=True)\n",
    "\n",
    "# Display the first five rows\n",
    "print(tesla_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6e6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Revenue\n",
      "48  2010-09-30       31\n",
      "49  2010-06-30       28\n",
      "50  2010-03-31       21\n",
      "51  2009-09-30       46\n",
      "52  2009-06-30       27\n"
     ]
    }
   ],
   "source": [
    "#Question 2: Use Webscraping to Extract Tesla Revenue Data\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create an Empty DataFrame\n",
    "tesla_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\n",
    "\n",
    "# Step 2: Download and parse the webpage\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/revenue.htm\"\n",
    "response = requests.get(url)\n",
    "html_data = response.text\n",
    "soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "\n",
    "# Step 3: Isolate the Tesla Quarterly Revenue table (second table on the page)\n",
    "tbody = soup.find_all(\"tbody\")[1]\n",
    "\n",
    "# Step 4: Extract data from rows\n",
    "for row in tbody.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) == 2:\n",
    "        date = cols[0].text.strip()\n",
    "        revenue = cols[1].text.strip()\n",
    "        tesla_revenue = pd.concat(\n",
    "            [tesla_revenue, pd.DataFrame({\"Date\": [date], \"Revenue\": [revenue]})],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "# Step 5: Clean the Revenue column\n",
    "tesla_revenue[\"Revenue\"] = tesla_revenue[\"Revenue\"].str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "\n",
    "# Your added cleaning lines:\n",
    "tesla_revenue.dropna(inplace=True)  # Remove rows with any NaN values\n",
    "tesla_revenue = tesla_revenue[tesla_revenue['Revenue'] != \"\"]  # Remove rows with empty Revenue strings\n",
    "\n",
    "# Convert Revenue to numeric for analysis\n",
    "tesla_revenue[\"Revenue\"] = pd.to_numeric(tesla_revenue[\"Revenue\"])\n",
    "\n",
    "# Reset the index\n",
    "tesla_revenue.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display cleaned DataFrame\n",
    "print(tesla_revenue.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c0b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                      Date      Open      High       Low     Close  \\\n",
      "0      0 2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667   \n",
      "1      1 2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667   \n",
      "2      2 2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000   \n",
      "3      3 2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   \n",
      "4      4 2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000   \n",
      "\n",
      "      Volume  Dividends  Stock Splits  \n",
      "0  281494500        0.0           0.0  \n",
      "1  257806500        0.0           0.0  \n",
      "2  123282000        0.0           0.0  \n",
      "3   77097000        0.0           0.0  \n",
      "4  103003500        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "#Question 3: Use yfinance to Extract Stock Data\n",
    "#Using the Ticker function enter the ticker symbol of the stock we want to extract data on to create a ticker object.\n",
    "#The stock is GameStop and its ticker symbol is GME.\n",
    "import yfinance as yf\n",
    "\n",
    "# Create ticker object for Tesla\n",
    "GameStop = yf.Ticker(\"GME\")\n",
    "\n",
    "# Extract historical stock data with maximum period\n",
    "GameStop_data = GameStop.history(period=\"max\")\n",
    "\n",
    "# Reset index inplace\n",
    "tesla_data.reset_index(inplace=True)\n",
    "\n",
    "# Display the first five rows\n",
    "print(tesla_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e88000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Revenue\n",
      "57  2006-01-31     1667\n",
      "58  2005-10-31      534\n",
      "59  2005-07-31      416\n",
      "60  2005-04-30      475\n",
      "61  2005-01-31      709\n"
     ]
    }
   ],
   "source": [
    "Question 4: Use Webscraping to Extract GME Revenue Data\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Create an Empty DataFrame\n",
    "GME_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\n",
    "\n",
    "# Step 2: Download and parse the webpage\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/stock.html\"\n",
    "response = requests.get(url)\n",
    "html_data_2 = response.text\n",
    "soup = BeautifulSoup(html_data_2, \"html.parser\")\n",
    "\n",
    "# Step 3: Isolate the GME Quarterly Revenue table (second table on the page)\n",
    "tbody = soup.find_all(\"tbody\")[1]\n",
    "\n",
    "# Step 4: Extract data from rows\n",
    "for row in tbody.find_all(\"tr\"):\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) == 2:\n",
    "        date = cols[0].text.strip()\n",
    "        revenue = cols[1].text.strip()\n",
    "        GME_revenue = pd.concat(\n",
    "            [GME_revenue, pd.DataFrame({\"Date\": [date], \"Revenue\": [revenue]})],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "# Step 5: Clean the Revenue column\n",
    "GME_revenue[\"Revenue\"] = GME_revenue[\"Revenue\"].str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "\n",
    "# Clean null or empty entries\n",
    "GME_revenue.dropna(inplace=True)\n",
    "GME_revenue = GME_revenue[GME_revenue[\"Revenue\"] != \"\"]\n",
    "\n",
    "# Convert Revenue to numeric\n",
    "GME_revenue[\"Revenue\"] = pd.to_numeric(GME_revenue[\"Revenue\"])\n",
    "\n",
    "# Reset the index\n",
    "GME_revenue.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the last 5 rows\n",
    "print(GME_revenue.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1d564cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My Account\\AppData\\Local\\Temp\\ipykernel_33088\\2139887379.py:15: UserWarning:\n",
      "\n",
      "The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "\n",
      "C:\\Users\\My Account\\anaconda3\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:106: FutureWarning:\n",
      "\n",
      "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "\n",
      "C:\\Users\\My Account\\AppData\\Local\\Temp\\ipykernel_33088\\2139887379.py:16: UserWarning:\n",
      "\n",
      "The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '$1,021'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     fig_html \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mto_html()\n\u001b[0;32m     28\u001b[0m     display(HTML(fig_html))\n\u001b[1;32m---> 30\u001b[0m make_graph(tesla_data, tesla_revenue, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesla\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m, in \u001b[0;36mmake_graph\u001b[1;34m(stock_data, revenue_data, stock)\u001b[0m\n\u001b[0;32m     14\u001b[0m revenue_data_specific \u001b[38;5;241m=\u001b[39m revenue_data[revenue_data\u001b[38;5;241m.\u001b[39mDate \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-04-30\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(stock_data_specific\u001b[38;5;241m.\u001b[39mDate, infer_datetime_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), y\u001b[38;5;241m=\u001b[39mstock_data_specific\u001b[38;5;241m.\u001b[39mClose\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShare Price\u001b[39m\u001b[38;5;124m\"\u001b[39m), row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(revenue_data_specific\u001b[38;5;241m.\u001b[39mDate, infer_datetime_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), y\u001b[38;5;241m=\u001b[39mrevenue_data_specific\u001b[38;5;241m.\u001b[39mRevenue\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m), row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_xaxes(title_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_xaxes(title_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '$1,021'"
     ]
    }
   ],
   "source": [
    "#Question 5: Plot Tesla Stock Graph\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"), vertical_spacing = .3)\n",
    "    stock_data_specific = stock_data[stock_data.Date <= '2021-06-14']\n",
    "    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True), y=stock_data_specific.Close.astype(\"float\"), name=\"Share Price\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True), y=revenue_data_specific.Revenue.astype(\"float\"), name=\"Revenue\"), row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    fig.update_layout(showlegend=False,\n",
    "    height=900,\n",
    "    title=stock,\n",
    "    xaxis_rangeslider_visible=True)\n",
    "    fig.show()\n",
    "    from IPython.display import display, HTML\n",
    "    fig_html = fig.to_html()\n",
    "    display(HTML(fig_html))\n",
    "\n",
    "make_graph(tesla_data, tesla_revenue, 'Tesla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfac79bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Assuming tesla_data and tesla_revenue are already defined and cleaned\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m tesla_revenue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tesla_revenue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m tesla_revenue\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     56\u001b[0m tesla_revenue \u001b[38;5;241m=\u001b[39m tesla_revenue[tesla_revenue[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6204\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6198\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6199\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6201\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6202\u001b[0m ):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:190\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:244\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    241\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1, shared_xaxes=True,\n",
    "        subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"),\n",
    "        vertical_spacing=0.3\n",
    "    )\n",
    "    \n",
    "    stock_data_specific = stock_data[stock_data.Date <= '2021-06-14']\n",
    "    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True),\n",
    "        y=stock_data_specific.Close.astype(\"float\"),\n",
    "        name=\"Share Price\"\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True),\n",
    "        y=revenue_data_specific.Revenue.astype(\"float\"),\n",
    "        name=\"Revenue\"\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        height=900,\n",
    "        title=stock,\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "    showlegend=False,\n",
    "    height=900,\n",
    "    title=f\"{stock} Stock Price and Revenue (Up to June 2021)\",\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "# Assuming tesla_data and tesla_revenue are already defined and cleaned\n",
    "tesla_revenue[\"Revenue\"] = tesla_revenue[\"Revenue\"].str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "tesla_revenue.dropna(inplace=True)\n",
    "tesla_revenue = tesla_revenue[tesla_revenue[\"Revenue\"] != \"\"]\n",
    "tesla_revenue[\"Revenue\"] = pd.to_numeric(tesla_revenue[\"Revenue\"])\n",
    "\n",
    "# Now call the plotting function\n",
    "make_graph(tesla_data, tesla_revenue, 'Tesla')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38050f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\My Account\\AppData\\Local\\Temp\\ipykernel_33088\\2031746283.py:24: UserWarning:\n",
      "\n",
      "The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "\n",
      "C:\\Users\\My Account\\AppData\\Local\\Temp\\ipykernel_33088\\2031746283.py:30: UserWarning:\n",
      "\n",
      "The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_35.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1, shared_xaxes=True,\n",
    "        subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"),\n",
    "        vertical_spacing=0.3\n",
    "    )\n",
    "    \n",
    "    stock_data_specific = stock_data[stock_data.Date <= '2021-06-14']\n",
    "    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True),\n",
    "        y=stock_data_specific.Close.astype(\"float\"),\n",
    "        name=\"Share Price\"\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True),\n",
    "        y=revenue_data_specific.Revenue.astype(\"float\"),\n",
    "        name=\"Revenue\"\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        height=900,\n",
    "        title=stock,\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "# Assuming tesla_data and tesla_revenue are already defined and cleaned\n",
    "tesla_revenue[\"Revenue\"] = tesla_revenue[\"Revenue\"].astype(str)\n",
    "tesla_revenue[\"Revenue\"] = tesla_revenue[\"Revenue\"].str.replace(\"$\", \"\", regex=False).str.replace(\",\", \"\", regex=False)\n",
    "tesla_revenue.dropna(inplace=True)\n",
    "tesla_revenue = tesla_revenue[tesla_revenue[\"Revenue\"] != \"\"]\n",
    "tesla_revenue[\"Revenue\"] = pd.to_numeric(tesla_revenue[\"Revenue\"])\n",
    "\n",
    "# Now call the plotting function\n",
    "make_graph(tesla_data, tesla_revenue, 'Tesla')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e82a558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_45.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question 6: Plot GameStop Stock Graph \n",
    "#Use the make_graph function to plot the graph of GameStop Stock Data, also provide a title for the graph. \n",
    "#The structure to call the make_graph function is make_graph(gme_data, gme_revenue, 'GameStop'). \n",
    "#Note the graph will only show data upto June 2021.\n",
    "# Clean GameStop revenue data\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\"\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1, shared_xaxes=True,\n",
    "        subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"),\n",
    "        vertical_spacing=0.3\n",
    "    )\n",
    "    \n",
    "    stock_data_specific = stock_data[stock_data.Date <= '2021-06-14']\n",
    "    revenue_data_specific = revenue_data[revenue_data.Date <= '2021-04-30']\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.to_datetime(stock_data_specific.Date, infer_datetime_format=True),\n",
    "        y=stock_data_specific.Close.astype(\"float\"),\n",
    "        name=\"Share Price\"\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pd.to_datetime(revenue_data_specific.Date, infer_datetime_format=True),\n",
    "        y=revenue_data_specific.Revenue.astype(\"float\"),\n",
    "        name=\"Revenue\"\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        height=900,\n",
    "        title=stock,\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "url = \"https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue\"\n",
    "html_data = requests.get(url).text\n",
    "soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "\n",
    "tables = soup.find_all(\"table\")\n",
    "gme_revenue = pd.DataFrame(columns=[\"Date\", \"Revenue\"])\n",
    "\n",
    "for table in tables:\n",
    "    if \"GameStop Quarterly Revenue\" in str(table):\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) == 2:\n",
    "                date = cols[0].text.strip()\n",
    "                revenue = cols[1].text.strip()\n",
    "                gme_revenue = pd.concat([gme_revenue, pd.DataFrame([[date, revenue]], columns=[\"Date\", \"Revenue\"])], ignore_index=True)\n",
    "\n",
    "gme_revenue[\"Revenue\"] = gme_revenue[\"Revenue\"].astype(str)\n",
    "gme_revenue[\"Revenue\"] = gme_revenue[\"Revenue\"].str.replace(\"$\", \"\", regex=False).str.replace(\",\", \"\", regex=False)\n",
    "gme_revenue.dropna(inplace=True)\n",
    "gme_revenue = gme_revenue[gme_revenue[\"Revenue\"] != \"\"]\n",
    "gme_revenue[\"Revenue\"] = pd.to_numeric(gme_revenue[\"Revenue\"])\n",
    "\n",
    "# Plot GameStop stock data and revenue\n",
    "gme = yf.Ticker(\"GME\")\n",
    "gme_data = gme.history(period=\"max\")\n",
    "gme_data.reset_index(inplace=True)\n",
    "make_graph(gme_data, gme_revenue, 'GameStop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22484dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
